{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_chroma import Chroma \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from retriever import Retriever\n",
    "from evaluator import RetrievalEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_score.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['embed', 'bm25', 'hybrid']\n",
    "embed_model_names = [\"all-MiniLM-L6-v2\", \"BAAI/LLM-Embedder\", \"BAAI/bge-small-en-v1.5\"]\n",
    "dbs = [FAISS, Chroma]\n",
    "db_names = ['faiss', 'chroma']\n",
    "\n",
    "queries = [\"What are the lowest writing scores?\", \n",
    "           \"What are the highest reading scores?\", \n",
    "           \"What are the average math scores?\", \n",
    "           \"If parental level of education has the impact for reading score?\", \n",
    "           \"What's the best comprehensive score?\",\n",
    "           \"If food impacts writing score?\"]\n",
    "\n",
    "relevant_docs = [['writing score'], \n",
    "                 ['reading score'], \n",
    "                 ['math score'], \n",
    "                 ['parental level of education','reading score'], \n",
    "                 ['writing score','reading score', 'math score'],\n",
    "                 ['lunch','writing score']]\n",
    "\n",
    "retriever_results = {'modes': [], \n",
    "                     'embed_model_names': [], \n",
    "                     'dbs': [], \n",
    "                     'Recall@k': [],\n",
    "                     'MRR': [],\n",
    "                     'queries': [],\n",
    "                     'retrieved_docs': []}\n",
    "\n",
    "for mode in modes:    \n",
    "    for embed_model_name in embed_model_names:       \n",
    "        for i in range(len(dbs)):           \n",
    "            try:\n",
    "                retriever = Retriever(mode=mode, embed_model_name=embed_model_name, db=dbs[i], top_k=5)\n",
    "                for j in range(len(queries)):\n",
    "                    retrieved_doc = retriever.retrieve_schema(queries[j], df, evaluate=True)\n",
    "                    relevant_doc = relevant_docs[j]\n",
    "                    evaluator = RetrievalEvaluator(retrieved_doc, relevant_doc)\n",
    "                    results = evaluator.evaluate()\n",
    "                    for key, value in results.items():\n",
    "                        retriever_results[key].append(value)\n",
    "                        \n",
    "                    retriever_results['modes'].append(mode)\n",
    "                    retriever_results['embed_model_names'].append(embed_model_name)\n",
    "                    retriever_results['dbs'].append(db_names[i])\n",
    "                    retriever_results['queries'].append(queries[j])\n",
    "                    retriever_results['retrieved_docs'].append(retrieved_doc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_df =pd.DataFrame(retriever_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_df.groupby(['modes', 'embed_model_names', 'dbs'])[['Recall@k', 'MRR']].agg(\n",
    "    recall_5_mean=('Recall@k', 'mean'), \n",
    "    recall_5_count=('Recall@k', 'count'),\n",
    "    mrr_mean=('MRR', 'mean'), \n",
    "    mrr_count=('MRR', 'count')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"embed + Chroma\" isn't a good combination choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retr_df[retr_df[['Recall@k', 'MRR']].sum(axis=1) < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_df[retr_df[['Recall@k', 'MRR']].sum(axis=1) < 2]['retrieved_docs'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表现都挺好的，选择一个方案用，并说明原因就行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate code generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from model import Model\n",
    "from retriever import Retriever\n",
    "from prompts import get_prompt, combined_template\n",
    "from agent import RAGAgent\n",
    "from evaluator import GenerCodeEvaluator\n",
    "from execute import extract_code\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_score.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate code generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(mode='hybrid', embed_model_name=\"BAAI/bge-small-en-v1.5\", db=FAISS, top_k=5)\n",
    "prompt = get_prompt(combined_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99291, Requested 1721. Please try again in 14m34.032999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99291, Requested 1718. Please try again in 14m31.122999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99290, Requested 1721. Please try again in 14m33.38s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99290, Requested 1721. Please try again in 14m33.001s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99290, Requested 1734. Please try again in 14m43.9s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99289, Requested 1724. Please try again in 14m34.895s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99289, Requested 1721. Please try again in 14m31.988s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99288, Requested 1718. Please try again in 14m29.058s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"llama3.1\", \"llama-3.3-70b-versatile\",\"mistral\", \"gemma2-9b-it\"]\n",
    "\n",
    "\n",
    "#Kwargs = [{'stable': {'temperature': 0.2,'top_k': 1}},\n",
    "#          {'diverse': {'temperature': 0.8, 'top_p': 0.95}},\n",
    "#          {'default': {}}]\n",
    "\n",
    "Kwargs = [{'stable': {'temperature': 0.1, 'top_p': 0.1}},\n",
    "          {'diverse': {'temperature': 0.8, 'top_p': 0.95}},\n",
    "          {'default': {}}]\n",
    "\n",
    "queries = [\"What are the lowest writing scores?\", \n",
    "           \"What are the highest reading scores?\", \n",
    "           \"What are the average math scores?\", \n",
    "           \"If parental level of education has the impact for reading score?\", \n",
    "           \"What's the best comprehensive score?\",\n",
    "           \"If food impacts writing score?\"]\n",
    "\n",
    "reference_codes = [\"df['writing score'].min()\", \n",
    "                 \"df['reading score'].max()\", \n",
    "                 \"df['math score'].mean()\", \n",
    "                 \"df.groupby('parental level of education')['reading score'].mean()\", \n",
    "                 \"df[['reading score', 'writing score', 'math score']].sum(axis=1).max()\",\n",
    "                 \"df.groupby('lunch')['writing score'].mean()\"]\n",
    "\n",
    "code_generator_results = {'model_names': [], \n",
    "                         'Exact Match': [],\n",
    "                         'F1 Score': [],\n",
    "                         'queries': [],\n",
    "                         'generateds': [],\n",
    "                         'param_types': []}\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    for dic_ in Kwargs:\n",
    "        for param_type, kwargs in dic_.items():\n",
    "            model = Model(model_name=model_name, **kwargs)\n",
    "            processor = RAGAgent(retriever, prompt, model, df)\n",
    "            for i in range(len(queries)):\n",
    "                try:\n",
    "                    generated = processor.processor(queries[i])\n",
    "                    generated_code = extract_code(generated)\n",
    "                    evaluator = GenerCodeEvaluator(generated_code, reference_codes[i])\n",
    "                    results = evaluator.evaluate()\n",
    "                    for key, value in results.items():\n",
    "                        code_generator_results[key].append(value)\n",
    "                    \n",
    "                    code_generator_results['model_names'].append(model_name)\n",
    "                    code_generator_results['queries'].append(queries[i])\n",
    "                    code_generator_results['generateds'].append(generated)\n",
    "                    code_generator_results['param_types'].append(param_type)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df = pd.DataFrame(code_generator_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>em_mean</th>\n",
       "      <th>em_count</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_names</th>\n",
       "      <th>param_types</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gemma2-9b-it</th>\n",
       "      <th>default</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">llama-3.3-70b-versatile</th>\n",
       "      <th>diverse</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama3.1</th>\n",
       "      <th>default</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mistral</th>\n",
       "      <th>default</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      em_mean  em_count   f1_mean  f1_count\n",
       "model_names             param_types                                        \n",
       "gemma2-9b-it            default      1.000000         6  1.000000         6\n",
       "                        diverse      1.000000         6  1.000000         6\n",
       "                        stable       1.000000         6  1.000000         6\n",
       "llama-3.3-70b-versatile diverse      0.750000         4  0.875000         4\n",
       "                        stable       1.000000         6  1.000000         6\n",
       "llama3.1                default      1.000000         6  1.000000         6\n",
       "                        diverse      0.833333         6  0.875000         6\n",
       "                        stable       1.000000         6  1.000000         6\n",
       "mistral                 default      0.833333         6  0.916667         6\n",
       "                        diverse      1.000000         6  1.000000         6\n",
       "                        stable       0.833333         6  0.833333         6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gen_df.groupby(['model_names', 'param_types'])[['Exact Match', 'F1 Score']].agg(\n",
    "    em_mean=('Exact Match', 'mean'), \n",
    "    em_count=('Exact Match', 'count'),\n",
    "    f1_mean=('F1 Score', 'mean'), \n",
    "    f1_count=('F1 Score', 'count')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose llama3.1 + stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate interpretation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from model import Model\n",
    "from retriever import Retriever\n",
    "from prompts import get_prompt, combined_template, interp_template\n",
    "from agent import RAGAgent, InterpAgent\n",
    "from evaluator import bert_score_f1\n",
    "from execute import parse_response\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_score.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate interpretation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(mode='hybrid', embed_model_name=\"BAAI/bge-small-en-v1.5\", db=FAISS, top_k=5)\n",
    "prompt = get_prompt(combined_template)\n",
    "code_model = Model(model_name=\"gemma2-9b-it\",temperature=0.2,top_p=0.1)\n",
    "processor = RAGAgent(retriever, prompt, code_model, df)\n",
    "interp_prompt = get_prompt(interp_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'The concluding response:'\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99902, Requested 398. Please try again in 4m18.676s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99895, Requested 426. Please try again in 4m36.747s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99887, Requested 375. Please try again in 3m46.299s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99882, Requested 375. Please try again in 3m41.225s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99874, Requested 374. Please try again in 3m33.964s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99867, Requested 543. Please try again in 5m53.773s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99860, Requested 398. Please try again in 3m42.107s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99852, Requested 426. Please try again in 4m0.084999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99846, Requested 375. Please try again in 3m10.756999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99839, Requested 375. Please try again in 3m4.672s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99832, Requested 374. Please try again in 2m57.528s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99825, Requested 543. Please try again in 5m17.249s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhnywfrpfrhb5r935e6ewy2h` service tier `on_demand` on : Limit 100000, Used 99818, Requested 398. Please try again in 3m6.316999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"llama3.1\", \"mistral\", \"gemma2-9b-it\",\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "Kwargs = [{'stable': {'temperature': 0.2,'top_p': 0.1}},\n",
    "          {'diverse': {'temperature': 0.8, 'top_p': 0.9}},\n",
    "          {'default': {}}]\n",
    "\n",
    "queries = [\"What are the lowest writing scores?\", \n",
    "           \"What are the highest reading scores?\", \n",
    "           \"What are the average math scores?\", \n",
    "           \"If parental level of education has the impact for reading score?\", \n",
    "           \"What's the best comprehensive score?\",\n",
    "           \"If food impacts writing score?\"]\n",
    "\n",
    "references = [[\"The relative result indicates that the lowest writing scores are 22.\"], \n",
    "              [\"The highest reading scores achieved are 86.\"], \n",
    "              [\"The calculated result indicates that the average math scores among the given data is approximately 63.85, suggesting a relatively moderate performance in this subject area.\"], \n",
    "              [\"The relative result indicates that there is a significant difference in reading scores across different levels of parental education, suggesting that parental level of education does have an impact on reading performance.\"], \n",
    "              [\"The best comprehensive score is 261, indicating that the sum of reading, writing, and math scores for this particular group or individual is the highest among all available data.\"],\n",
    "              [\"The relative data suggests that students who received free or reduced lunch had a significantly higher mean writing score (65.7) compared to those who received standard lunch (62.2), indicating a positive impact of food on writing performance.\"]]\n",
    "\n",
    "generator_results = {'model_names': [], \n",
    "                    'bert_score_f1': [],\n",
    "                    'queries': [],\n",
    "                    'responses': [],\n",
    "                    'param_types': []}\n",
    "\n",
    "for model_name in model_names:\n",
    "    for dic_ in Kwargs:\n",
    "        for param_type, kwargs in dic_.items():\n",
    "            model = Model(model_name=model_name, **kwargs)\n",
    "            interp = InterpAgent(interp_prompt, model)\n",
    "            for i in range(len(queries)):\n",
    "                try:\n",
    "                    ctx = processor.invoke(queries[i])\n",
    "                    answer = interp.processor(ctx, queries[i])\n",
    "                    response = parse_response(answer)['The concluding response:']\n",
    "                    f1 = bert_score_f1([response], references[i])\n",
    "                    generator_results['bert_score_f1'].append(f1)\n",
    "                    generator_results['model_names'].append(model_name)\n",
    "                    generator_results['queries'].append(queries[i])\n",
    "                    generator_results['responses'].append(response)\n",
    "                    generator_results['param_types'].append(param_type)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_df = pd.DataFrame(generator_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_names</th>\n",
       "      <th>param_types</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gemma2-9b-it</th>\n",
       "      <th>default</th>\n",
       "      <td>0.811667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>0.811667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">llama-3.3-70b-versatile</th>\n",
       "      <th>default</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama3.1</th>\n",
       "      <th>default</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>0.871667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>0.890000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mistral</th>\n",
       "      <th>default</th>\n",
       "      <td>0.818333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diverse</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      f1_mean  f1_count\n",
       "model_names             param_types                    \n",
       "gemma2-9b-it            default      0.811667         6\n",
       "                        diverse      0.811667         6\n",
       "                        stable       0.810000         6\n",
       "llama-3.3-70b-versatile default      0.840000         1\n",
       "                        stable       0.825000         4\n",
       "llama3.1                default      0.866667         6\n",
       "                        diverse      0.871667         6\n",
       "                        stable       0.890000         6\n",
       "mistral                 default      0.818333         6\n",
       "                        diverse      0.800000         5\n",
       "                        stable       0.825000         6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interp_df.groupby(['model_names', 'param_types'])[['bert_score_f1']].agg(\n",
    "    f1_mean=('bert_score_f1', 'mean'), \n",
    "    f1_count=('bert_score_f1', 'count')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama3.1 + stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
